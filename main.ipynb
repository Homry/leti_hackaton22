{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcnn = MTCNN(image_size=160, margin=16)\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "import cv2\n",
    "face_cascade = cv2.CascadeClassifier('./cascade.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, SubsetRandomSampler\n",
    "import os\n",
    "from PIL import Image, ImageOps, ImageStat, ImageEnhance\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def brightness( im_file ):\n",
    "   im = Image.fromarray(im_file).convert('L')\n",
    "   stat = ImageStat.Stat(im)\n",
    "   return stat.mean[0]\n",
    "\n",
    "\n",
    "class LFW(Dataset):\n",
    "    def __init__(self, path_to_data, transform=None):\n",
    "        self.transform = transform\n",
    "        data_same_person = []\n",
    "        data_dif_person = []\n",
    "        with open(path_to_data, 'r') as f:\n",
    "            line = f.read()\n",
    "            line = line.split('\\n')\n",
    "            line = [i.split('\\t') for i in line]\n",
    "            [data_same_person.append(i) if len(i) == 3 else data_dif_person.append(i) for i in line]\n",
    "        data_same_person_res = []\n",
    "        for i in data_same_person:\n",
    "            if len(i[1]) == 1:\n",
    "                inp = f'./lfw/{i[0]}/{i[0]}_000{i[1]}.jpg'\n",
    "            elif len(i[1]) ==2:\n",
    "                inp = f'./lfw/{i[0]}/{i[0]}_00{i[1]}.jpg'\n",
    "            else:\n",
    "                inp = f'./lfw/{i[0]}/{i[0]}_0{i[1]}.jpg'\n",
    "            if len(i[2]) == 1:\n",
    "                tar = f'./lfw/{i[0]}/{i[0]}_000{i[2]}.jpg'\n",
    "            elif len(i[2]) ==2:\n",
    "                tar = f'./lfw/{i[0]}/{i[0]}_00{i[2]}.jpg'\n",
    "            else:\n",
    "                tar = f'./lfw/{i[0]}/{i[0]}_0{i[2]}.jpg'\n",
    "            data_same_person_res.append([inp, tar, 1.0])\n",
    "\n",
    "        #data_same_person_res = [[f'./lfw/{i[0]}/{i[0]}_000{i[1]}.jpg' if len(i[1]) == 1 else f'./lfw/{i[0]}/{i[0]}_00{i[1]}.jpg',\n",
    "                                 #f'./lfw/{i[0]}/{i[0]}_000{i[2]}.jpg' if len(i[2]) == 1 else f'./lfw/{i[0]}/{i[0]}_00{i[2]}.jpg',\n",
    "                                 #1.0] for i in data_same_person]\n",
    "        del (data_dif_person[-1])\n",
    "        data_dif_person_res = []\n",
    "        for i in data_dif_person:\n",
    "            if len(i[1]) == 1:\n",
    "                inp = f'./lfw/{i[0]}/{i[0]}_000{i[1]}.jpg'\n",
    "            elif len(i[1]) ==2:\n",
    "                inp = f'./lfw/{i[0]}/{i[0]}_00{i[1]}.jpg'\n",
    "            else:\n",
    "                inp = f'./lfw/{i[0]}/{i[0]}_0{i[1]}.jpg'\n",
    "            if len(i[3]) == 1:\n",
    "                tar = f'./lfw/{i[2]}/{i[2]}_000{i[3]}.jpg'\n",
    "            elif len(i[3]) ==2:\n",
    "                tar = f'./lfw/{i[2]}/{i[2]}_00{i[3]}.jpg'\n",
    "            else:\n",
    "                tar = f'./lfw/{i[2]}/{i[2]}_0{i[3]}.jpg'\n",
    "            data_dif_person_res.append([inp, tar, 0.0])\n",
    "        #data_dif_person_res = [[f'./lfw/{i[0]}/{i[0]}_000{i[1]}.jpg' if len(i[1]) == 1 else f'./lfw/{i[0]}/{i[0]}_00{i[1]}.jpg',\n",
    "        #                        f'./lfw/{i[2]}/{i[2]}_000{i[3]}.jpg' if len(i[3]) == 1 else f'./lfw/{i[2]}/{i[2]}_00{i[3]}.jpg',\n",
    "        #                        0.0] for i in data_dif_person]\n",
    "        self.data = data_same_person_res + data_dif_person_res\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    '''def __getitem__(self, index):\n",
    "        img_input = mtcnn(Image.open(self.data[index][0])).detach().numpy()\n",
    "        img_target = mtcnn(Image.open(self.data[index][1])).detach().numpy()\n",
    "        label = float(self.data[index][2])\n",
    "        return img_input, img_target, label'''\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_inp = cv2.imread(self.data[index][0])\n",
    "        img = img_inp.copy()\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        # Detect faces\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "        for (x, y, w, h) in faces:\n",
    "            faces = img_inp[y:y + h, x:x + w]\n",
    "        img_input = faces\n",
    "        img_input = cv2.cvtColor(img_input, cv2.COLOR_BGR2GRAY)\n",
    "        img_input = controller(img_input, 60)\n",
    "\n",
    "\n",
    "\n",
    "        test = Image.fromarray(img_input)\n",
    "        test = ImageOps.grayscale(test)\n",
    "\n",
    "        stat = ImageStat.Stat(test)\n",
    "        stat = stat.mean[0]\n",
    "        filter = ImageEnhance.Brightness(test)\n",
    "        image = filter.enhance(100/brightness(img_input))\n",
    "        image = np.asarray(image)\n",
    "        image = cv2.merge([image, image, image])\n",
    "        image = np.reshape(image, (3, image.shape[0], image.shape[1]))\n",
    "        image = np.resize(image, (3, 160, 160))\n",
    "\n",
    "\n",
    "        tar = cv2.imread(self.data[index][1])\n",
    "        img = tar.copy()\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "        for (x, y, w, h) in faces:\n",
    "            faces = tar[y:y + h, x:x + w]\n",
    "        img_target = faces\n",
    "        img_target = cv2.cvtColor(img_target, cv2.COLOR_BGR2GRAY)\n",
    "        img_target = cv2.merge([img_target, img_target, img_target])\n",
    "        img_target = np.reshape(img_target, (3, img_target.shape[0], img_target.shape[0]))\n",
    "        img_target = np.resize(img_target, (3, 160, 160))\n",
    "        label = float(self.data[index][2])\n",
    "        return image, img_target, label\n",
    "\n",
    "\n",
    "class LFW_Train(Dataset):\n",
    "    def __init__(self, path_to_data, transform=None):\n",
    "        self.transform = transform\n",
    "        data_same_person = []\n",
    "        data_dif_person = []\n",
    "        with open(path_to_data, 'r') as f:\n",
    "            line = f.read()\n",
    "            line = line.split('\\n')\n",
    "            line = [i.split('\\t') for i in line]\n",
    "            [data_same_person.append(i) if len(i) == 3 else data_dif_person.append(i) for i in line]\n",
    "        res = []\n",
    "        for i in data_same_person:\n",
    "            for j in data_dif_person:\n",
    "                if i[0] in j:\n",
    "                    index = j.index(i[0])\n",
    "                    if index == 0:\n",
    "                        index = 2\n",
    "                    else:\n",
    "                        index = 0\n",
    "                    tmp = i.copy()\n",
    "                    tmp.append(j[index])\n",
    "                    tmp.append(j[index+1])\n",
    "                    res.append(tmp)\n",
    "        data_res = []\n",
    "        for i in res:\n",
    "            if len(i[1]) == 1:\n",
    "                anchor = f'./lfw/{i[0]}/{i[0]}_000{i[1]}.jpg'\n",
    "            elif len(i[1]) == 2:\n",
    "                anchor = f'./lfw/{i[0]}/{i[0]}_00{i[1]}.jpg'\n",
    "            else:\n",
    "                anchor = f'./lfw/{i[0]}/{i[0]}_0{i[1]}.jpg'\n",
    "            if len(i[2]) == 1:\n",
    "                pos = f'./lfw/{i[0]}/{i[0]}_000{i[2]}.jpg'\n",
    "            elif len(i[2]) == 2:\n",
    "                pos = f'./lfw/{i[0]}/{i[0]}_00{i[2]}.jpg'\n",
    "            else:\n",
    "                pos = f'./lfw/{i[0]}/{i[0]}_0{i[2]}.jpg'\n",
    "            if len(i[4]) == 1:\n",
    "                neg = f'./lfw/{i[3]}/{i[3]}_000{i[4]}.jpg'\n",
    "            elif len(i[4]) == 2:\n",
    "                neg = f'./lfw/{i[3]}/{i[3]}_00{i[4]}.jpg'\n",
    "            else:\n",
    "                neg = f'./lfw/{i[3]}/{i[3]}_0{i[4]}.jpg'\n",
    "            data_res.append([anchor, pos, neg])\n",
    "        self.data = data_res\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    '''def __getitem__(self, index):\n",
    "        img_input = mtcnn(Image.open(self.data[index][0])).detach().numpy()\n",
    "        img_target = mtcnn(Image.open(self.data[index][1])).detach().numpy()\n",
    "        label = float(self.data[index][2])\n",
    "        return img_input, img_target, label'''\n",
    "\n",
    "    ''' def __getitem__(self, index):\n",
    "        img_inp = Image.open(self.data[index][0])\n",
    "        img_inp = np.asarray(ImageOps.grayscale(img_inp))\n",
    "        img_inp = cv2.merge([img_inp, img_inp, img_inp])\n",
    "        anchor = mtcnn(img_inp).detach().numpy()\n",
    "\n",
    "        pos = Image.open(self.data[index][1])\n",
    "        pos = np.asarray(ImageOps.grayscale(pos))\n",
    "        pos = cv2.merge([pos, pos, pos])\n",
    "        pos = mtcnn(pos).detach().numpy()\n",
    "\n",
    "        tar = Image.open(self.data[index][2])\n",
    "        tar = np.asarray(ImageOps.grayscale(tar))\n",
    "        tar = cv2.merge([tar, tar, tar])\n",
    "        neg = mtcnn(tar).detach().numpy()\n",
    "\n",
    "        return anchor, pos, neg'''\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "\n",
    "        img_inp = cv2.imread(self.data[index][0])\n",
    "        img = img_inp.copy()\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            faces = img_inp[y:y + h, x:x + w]\n",
    "        anchor = faces\n",
    "        #print(self.data[index][0])\n",
    "        anchor = cv2.cvtColor(anchor, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "        img_inp = cv2.imread(self.data[index][1])\n",
    "        img = img_inp.copy()\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "        for (x, y, w, h) in faces:\n",
    "            faces = img_inp[y:y + h, x:x + w]\n",
    "        pos = faces\n",
    "        #print(self.data[index][1])\n",
    "        pos = cv2.cvtColor(pos, cv2.COLOR_BGR2GRAY)\n",
    "        pos = cv2.merge([pos, pos, pos])\n",
    "        pos = np.reshape(pos, (3, pos.shape[0], pos.shape[0]))\n",
    "\n",
    "        img_inp = cv2.imread(self.data[index][2])\n",
    "        img = img_inp.copy()\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "        for (x, y, w, h) in faces:\n",
    "            faces = img_inp[y:y + h, x:x + w]\n",
    "        neg = faces\n",
    "        #print(self.data[index][2])\n",
    "        neg = cv2.cvtColor(neg, cv2.COLOR_BGR2GRAY)\n",
    "        neg = cv2.merge([neg, neg, neg])\n",
    "        neg = np.reshape(neg, (3, neg.shape[0], neg.shape[0]))\n",
    "\n",
    "\n",
    "        if self.transform:\n",
    "            anchor = self.transform(image=anchor)['image']\n",
    "            anchor = controller(anchor)\n",
    "            anchor = cv2.merge([anchor, anchor, anchor])\n",
    "            anchor = np.reshape(anchor, (3, anchor.shape[0], anchor.shape[0]))\n",
    "        anchor = np.resize(anchor, (3, 160, 160))\n",
    "        pos = np.resize(pos, (3, 160, 160))\n",
    "        neg = np.resize(neg, (3, 160, 160))\n",
    "        return np.array(anchor, dtype=np.float), np.array(pos, dtype=np.float), np.array(neg, dtype=np.float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import random\n",
    "def controller(img, brightness=40, contrast=127):\n",
    "    p = random.randint(1, 3)\n",
    "    if p != 2:\n",
    "        return img\n",
    "    p = random.randint(1, 3)\n",
    "    if p == 1:\n",
    "        brightness = 80\n",
    "    elif p==2:\n",
    "        brightness = 60\n",
    "    else:\n",
    "        brightness = 40\n",
    "    brightness = int((brightness - 0) * (255 - (-255)) / (510 - 0) + (-255))\n",
    "    contrast = int((contrast - 0) * (127 - (-127)) / (254 - 0) + (-127))\n",
    "    if brightness != 0:\n",
    "        if brightness > 0:\n",
    "            shadow = brightness\n",
    "            max = 255\n",
    "        else:\n",
    "            shadow = 0\n",
    "            max = 255 + brightness\n",
    "        al_pha = (max - shadow) / 255\n",
    "        ga_mma = shadow\n",
    "        # The function addWeighted calculates\n",
    "        # the weighted sum of two arrays\n",
    "        cal = cv2.addWeighted(img, al_pha,\n",
    "                              img, 0, ga_mma)\n",
    "    else:\n",
    "        cal = img\n",
    "    if contrast != 0:\n",
    "        Alpha = float(131 * (contrast + 127)) / (127 * (131 - contrast))\n",
    "        Gamma = 127 * (1 - Alpha)\n",
    "        # The function addWeighted calculates\n",
    "        # the weighted sum of two arrays\n",
    "        cal = cv2.addWeighted(cal, Alpha,\n",
    "                              cal, 0, Gamma)\n",
    "    return cal"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "train_dataset = LFW_Train(\"./pairsDevTrain.txt\",\n",
    "                        transform=A.Compose([\n",
    "                                A.HorizontalFlip(p=0.5),\n",
    "                                A.Rotate(limit=(0, 15), p=0.5)\n",
    "                            ])\n",
    "                      )\n",
    "test_dataset = LFW(\"./pairsDevTest.txt\"\n",
    "                      )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "resnet = resnet.to(device)\n",
    "batch_size = 32\n",
    "\n",
    "data_size = len(train_dataset)\n",
    "validation_fraction = .2\n",
    "\n",
    "\n",
    "val_split = int(np.floor((validation_fraction) * data_size))\n",
    "indices = list(range(data_size))\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "val_indices, train_indices = indices[:val_split], indices[val_split:]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                           sampler=train_sampler)\n",
    "val_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                         sampler=val_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def compute_f1(model, grt):\n",
    "    model.eval()\n",
    "    for x, y, z in grt:\n",
    "        x = x.to(device=device)\n",
    "        y = y.to(device=device)\n",
    "        z = z.to(device=device)\n",
    "        predictx = model(x.float())\n",
    "        predicty = model(y.float())\n",
    "        predictz = model(z.float())\n",
    "        pred = []\n",
    "        label = []\n",
    "        for i in range(len(predictx)):\n",
    "            pred.append((1+sum(predictx[i]*predicty[i]))/2)\n",
    "            pred.append((1+sum(predictx[i]*predictz[i]))/2)\n",
    "            label.append(1.0)\n",
    "            label.append(0.0)\n",
    "        pred = np.array(list(map(lambda x: int(x > 0.8), pred)))\n",
    "        label = np.array(label)\n",
    "        return f1_score(label, pred)\n",
    "\n",
    "def compute_f1_test(model, grt):\n",
    "    model.eval()\n",
    "    for x, y, label in grt:\n",
    "        x = x.to(device=device)\n",
    "        y = y.to(device=device)\n",
    "        predictx = model(x.float())\n",
    "        predicty = model(y.float())\n",
    "        pred = []\n",
    "        for i in range(len(predictx)):\n",
    "            pred.append((1+sum(predictx[i]*predicty[i]))/2)\n",
    "        pred = np.array(list(map(lambda x: int(x > 0.8), pred)))\n",
    "        return f1_score(label, pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, loss, optimizer, num_epochs):\n",
    "    loss_history = []\n",
    "    val_history = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # Enter train mode\n",
    "        loss_accum = 0\n",
    "        for i_step, (a, p, n) in enumerate(train_loader):\n",
    "            a_gpu = torch.tensor(a, dtype=torch.float).to(device)\n",
    "            p_gpu = torch.tensor(p, dtype=torch.float).to(device)\n",
    "            n_gpu = torch.tensor(n, dtype=torch.float).to(device)\n",
    "            a_gpu = a_gpu.requires_grad_(True)\n",
    "            p_gpu = p_gpu.requires_grad_(True)\n",
    "            n_gpu = n_gpu.requires_grad_(True)\n",
    "            a_gpu = model(a_gpu)\n",
    "            p_gpu = model(p_gpu)\n",
    "            n_gpu = model(n_gpu)\n",
    "            #a_gpu.requires_grad = True\n",
    "            #p_gpu.requires_grad = True\n",
    "            #n_gpu.requires_grad = True\n",
    "            loss_value = loss(a_gpu, p_gpu, n_gpu)\n",
    "            optimizer.zero_grad()\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            loss_accum += loss_value\n",
    "\n",
    "        ave_loss = loss_accum / i_step\n",
    "        val_f1 = compute_f1(model, val_loader)\n",
    "\n",
    "        loss_history.append(float(ave_loss))\n",
    "        val_history.append(val_f1)\n",
    "\n",
    "        print(\"%f Average loss: %f,, Val f1: %f\" % (epoch, ave_loss, val_f1))\n",
    "\n",
    "    return loss_history, val_history"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000 Average loss: 1.038496,, Val f1: 0.060606\n",
      "1.000000 Average loss: 1.033023,, Val f1: 0.000000\n",
      "2.000000 Average loss: 1.007635,, Val f1: 0.263158\n",
      "3.000000 Average loss: 0.972124,, Val f1: 0.054054\n",
      "4.000000 Average loss: 0.940545,, Val f1: 0.060606\n",
      "5.000000 Average loss: 0.902868,, Val f1: 0.000000\n",
      "6.000000 Average loss: 0.875049,, Val f1: 0.055556\n",
      "7.000000 Average loss: 0.838855,, Val f1: 0.270270\n",
      "8.000000 Average loss: 0.769179,, Val f1: 0.171429\n",
      "9.000000 Average loss: 0.755879,, Val f1: 0.210526\n",
      "10.000000 Average loss: 0.683926,, Val f1: 0.216216\n",
      "11.000000 Average loss: 0.665764,, Val f1: 0.222222\n",
      "12.000000 Average loss: 0.572299,, Val f1: 0.171429\n",
      "13.000000 Average loss: 0.543477,, Val f1: 0.315789\n",
      "14.000000 Average loss: 0.478973,, Val f1: 0.222222\n",
      "15.000000 Average loss: 0.438039,, Val f1: 0.222222\n",
      "16.000000 Average loss: 0.370418,, Val f1: 0.390244\n",
      "17.000000 Average loss: 0.331227,, Val f1: 0.222222\n",
      "18.000000 Average loss: 0.292702,, Val f1: 0.390244\n",
      "19.000000 Average loss: 0.251439,, Val f1: 0.380952\n",
      "20.000000 Average loss: 0.216418,, Val f1: 0.279070\n",
      "21.000000 Average loss: 0.250188,, Val f1: 0.418605\n",
      "22.000000 Average loss: 0.223864,, Val f1: 0.489796\n",
      "23.000000 Average loss: 0.187279,, Val f1: 0.350000\n",
      "24.000000 Average loss: 0.173326,, Val f1: 0.530612\n",
      "25.000000 Average loss: 0.151953,, Val f1: 0.530612\n",
      "26.000000 Average loss: 0.127586,, Val f1: 0.730769\n",
      "27.000000 Average loss: 0.158317,, Val f1: 0.566038\n",
      "28.000000 Average loss: 0.148458,, Val f1: 0.444444\n",
      "29.000000 Average loss: 0.124362,, Val f1: 0.510638\n",
      "30.000000 Average loss: 0.161812,, Val f1: 0.520000\n",
      "31.000000 Average loss: 0.126772,, Val f1: 0.576923\n",
      "32.000000 Average loss: 0.146938,, Val f1: 0.458333\n",
      "33.000000 Average loss: 0.131944,, Val f1: 0.400000\n",
      "34.000000 Average loss: 0.104818,, Val f1: 0.541667\n",
      "35.000000 Average loss: 0.098284,, Val f1: 0.465116\n",
      "36.000000 Average loss: 0.081589,, Val f1: 0.465116\n",
      "37.000000 Average loss: 0.070186,, Val f1: 0.465116\n",
      "38.000000 Average loss: 0.072489,, Val f1: 0.521739\n",
      "39.000000 Average loss: 0.075330,, Val f1: 0.703704\n",
      "40.000000 Average loss: 0.059370,, Val f1: 0.612245\n",
      "41.000000 Average loss: 0.067579,, Val f1: 0.500000\n",
      "42.000000 Average loss: 0.054837,, Val f1: 0.510638\n",
      "43.000000 Average loss: 0.100552,, Val f1: 0.560000\n",
      "44.000000 Average loss: 0.084527,, Val f1: 0.560000\n",
      "45.000000 Average loss: 0.098681,, Val f1: 0.571429\n",
      "46.000000 Average loss: 0.068175,, Val f1: 0.538462\n",
      "47.000000 Average loss: 0.058787,, Val f1: 0.588235\n",
      "48.000000 Average loss: 0.069058,, Val f1: 0.528302\n",
      "49.000000 Average loss: 0.054330,, Val f1: 0.541667\n",
      "50.000000 Average loss: 0.064825,, Val f1: 0.488889\n",
      "51.000000 Average loss: 0.076823,, Val f1: 0.631579\n",
      "52.000000 Average loss: 0.092755,, Val f1: 0.701754\n",
      "53.000000 Average loss: 0.065476,, Val f1: 0.530612\n",
      "54.000000 Average loss: 0.036590,, Val f1: 0.541667\n",
      "55.000000 Average loss: 0.064877,, Val f1: 0.607143\n",
      "56.000000 Average loss: 0.044605,, Val f1: 0.592593\n",
      "57.000000 Average loss: 0.050732,, Val f1: 0.545455\n",
      "58.000000 Average loss: 0.062053,, Val f1: 0.583333\n",
      "59.000000 Average loss: 0.075857,, Val f1: 0.588235\n",
      "60.000000 Average loss: 0.064527,, Val f1: 0.576923\n",
      "61.000000 Average loss: 0.045196,, Val f1: 0.382979\n",
      "62.000000 Average loss: 0.038353,, Val f1: 0.583333\n",
      "63.000000 Average loss: 0.020060,, Val f1: 0.530612\n",
      "64.000000 Average loss: 0.043553,, Val f1: 0.480000\n",
      "65.000000 Average loss: 0.036219,, Val f1: 0.727273\n",
      "66.000000 Average loss: 0.035074,, Val f1: 0.448980\n",
      "67.000000 Average loss: 0.029243,, Val f1: 0.458333\n",
      "68.000000 Average loss: 0.040686,, Val f1: 0.489796\n",
      "69.000000 Average loss: 0.045793,, Val f1: 0.592593\n",
      "70.000000 Average loss: 0.024246,, Val f1: 0.600000\n",
      "71.000000 Average loss: 0.025614,, Val f1: 0.530612\n",
      "72.000000 Average loss: 0.033551,, Val f1: 0.549020\n",
      "73.000000 Average loss: 0.041919,, Val f1: 0.530612\n",
      "74.000000 Average loss: 0.039753,, Val f1: 0.690909\n",
      "75.000000 Average loss: 0.030747,, Val f1: 0.409091\n",
      "76.000000 Average loss: 0.024413,, Val f1: 0.480000\n",
      "77.000000 Average loss: 0.024827,, Val f1: 0.640000\n",
      "78.000000 Average loss: 0.029652,, Val f1: 0.603774\n",
      "79.000000 Average loss: 0.022981,, Val f1: 0.655172\n",
      "80.000000 Average loss: 0.034103,, Val f1: 0.576923\n",
      "81.000000 Average loss: 0.043208,, Val f1: 0.654545\n",
      "82.000000 Average loss: 0.059393,, Val f1: 0.530612\n",
      "83.000000 Average loss: 0.034940,, Val f1: 0.678571\n",
      "84.000000 Average loss: 0.027966,, Val f1: 0.666667\n",
      "85.000000 Average loss: 0.018750,, Val f1: 0.641509\n",
      "86.000000 Average loss: 0.035311,, Val f1: 0.489796\n",
      "87.000000 Average loss: 0.037599,, Val f1: 0.592593\n",
      "88.000000 Average loss: 0.033914,, Val f1: 0.576923\n",
      "89.000000 Average loss: 0.033880,, Val f1: 0.678571\n",
      "90.000000 Average loss: 0.020472,, Val f1: 0.576923\n",
      "91.000000 Average loss: 0.025438,, Val f1: 0.603774\n",
      "92.000000 Average loss: 0.028866,, Val f1: 0.566038\n",
      "93.000000 Average loss: 0.023415,, Val f1: 0.666667\n",
      "94.000000 Average loss: 0.029906,, Val f1: 0.500000\n",
      "95.000000 Average loss: 0.017487,, Val f1: 0.448980\n",
      "96.000000 Average loss: 0.022427,, Val f1: 0.627451\n",
      "97.000000 Average loss: 0.020814,, Val f1: 0.653061\n",
      "98.000000 Average loss: 0.024987,, Val f1: 0.509804\n",
      "99.000000 Average loss: 0.027329,, Val f1: 0.642857\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.43902439024390244"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "params_old = list([param for name, param in resnet.named_parameters() if not name.startswith('logits.')])\n",
    "params_new = list([param for name, param in resnet.named_parameters() if name.startswith('logits.')])\n",
    "\n",
    "parameters = [\n",
    "    {'params': params_old, 'lr': 0.0001, 'momentum': 0.9},\n",
    "    {'params': params_new, 'lr': 0.001, 'momentum': 0.9}\n",
    "]\n",
    "optimizer = optim.SGD(resnet.parameters(), lr=0.001, momentum=0.9)\n",
    "loss = nn.TripletMarginLoss(margin=1.0, p=2)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "train_model(resnet, train_loader, val_loader, loss, optimizer, 100)\n",
    "compute_f1_test(resnet, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "torch.save(resnet.state_dict(), 'm1.w')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('pairs.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4504)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "resnet.load_state_dict(torch.load('./m1.w'))\n",
    "resnet.eval()\n",
    "resnet.to('cpu')\n",
    "x = []\n",
    "y = []\n",
    "label = []\n",
    "predictx = []\n",
    "predicty = []\n",
    "light = 100\n",
    "for i in data:\n",
    "\n",
    "    tmp = i[0].copy()\n",
    "    for s1 in range(len(tmp)):\n",
    "        for s2 in range(len(tmp[s1])):\n",
    "            if tmp[s1][s2] < 20:\n",
    "                tmp[s1][s2] = 30 - tmp[s1][s2]\n",
    "    test = Image.fromarray(tmp)\n",
    "    test = ImageOps.grayscale(test)\n",
    "    stat = ImageStat.Stat(test)\n",
    "    stat = stat.mean[0]\n",
    "    if stat >= light:\n",
    "        image = i[0]\n",
    "    else:\n",
    "        filter = ImageEnhance.Brightness(test)\n",
    "        image = filter.enhance(light/brightness(i[0]))\n",
    "        image = np.asarray(image)\n",
    "\n",
    "\n",
    "    #image = cv2.merge([i[0], i[0], i[0]])\n",
    "    image = cv2.merge([image, image, image])\n",
    "    image = np.reshape(image, (3, image.shape[0], image.shape[1]))\n",
    "    image = np.resize(image, (3, 160, 160))\n",
    "    x = torch.Tensor(np.array([image])).to('cpu')\n",
    "    predictx.append(resnet(x.float()).detach().numpy()[0])\n",
    "    target = cv2.merge([i[1], i[1], i[1]])\n",
    "    target = np.reshape(target, (3, target.shape[0], target.shape[1]))\n",
    "    target = np.resize(target, (3, 160, 160))\n",
    "    y = torch.Tensor(np.array([target])).to('cpu')\n",
    "    predicty.append(resnet(y.float()).detach().numpy()[0])\n",
    "pred = []\n",
    "for i in range(len(predictx)):\n",
    "    pred.append((1+sum(predictx[i]*predicty[i]))/2)\n",
    "\n",
    "pred = np.array(list(map(lambda x: int(x > 0.8), pred)))\n",
    "print(np.array([pred]).shape)\n",
    "with open('Аналитические_котики_3.npy', 'wb') as f:\n",
    "    np.save(f, np.array([pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4504\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "InceptionResnetV1(\n  (conv2d_1a): BasicConv2d(\n    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU()\n  )\n  (conv2d_2a): BasicConv2d(\n    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU()\n  )\n  (conv2d_2b): BasicConv2d(\n    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU()\n  )\n  (maxpool_3a): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2d_3b): BasicConv2d(\n    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU()\n  )\n  (conv2d_4a): BasicConv2d(\n    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU()\n  )\n  (conv2d_4b): BasicConv2d(\n    (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n    (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU()\n  )\n  (repeat_1): Sequential(\n    (0): Block35(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (branch2): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (1): Block35(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (branch2): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (2): Block35(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (branch2): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (3): Block35(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (branch2): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (4): Block35(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (branch2): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n  )\n  (mixed_6a): Mixed_6a(\n    (branch0): BasicConv2d(\n      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n    (branch1): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(256, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (2): BasicConv2d(\n        (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n    )\n    (branch2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (repeat_2): Sequential(\n    (0): Block17(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (1): Block17(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (2): Block17(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (3): Block17(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (4): Block17(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (5): Block17(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (6): Block17(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (7): Block17(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (8): Block17(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (9): Block17(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n  )\n  (mixed_7a): Mixed_7a(\n    (branch0): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n    )\n    (branch1): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n    )\n    (branch2): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (2): BasicConv2d(\n        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n    )\n    (branch3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (repeat_3): Sequential(\n    (0): Block8(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (1): Block8(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (2): Block8(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (3): Block8(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n    (4): Block8(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU()\n    )\n  )\n  (block8): Block8(\n    (branch0): BasicConv2d(\n      (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n    (branch1): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (2): BasicConv2d(\n        (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n    )\n    (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (avgpool_1a): AdaptiveAvgPool2d(output_size=1)\n  (dropout): Dropout(p=0.6, inplace=False)\n  (last_linear): Linear(in_features=1792, out_features=512, bias=False)\n  (last_bn): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (logits): Linear(in_features=512, out_features=8631, bias=True)\n)"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
